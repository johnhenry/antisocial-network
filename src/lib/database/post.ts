import type {
  Agent,
  Entity,
  File,
  FileProto,
  LangchainGenerator,
  Post,
  PostPlus,
} from "@/types/mod";
import type { BaseMessageChunk } from "@langchain/core/messages";

import {
  REL_BOOKMARKS,
  REL_CONTAINS,
  REL_ELICITS,
  REL_INSERTED,
  REL_PRECEDES,
  REL_REMEMBERS,
  TABLE_AGENT,
  TABLE_FILE,
  TABLE_POST,
} from "@/config/mod";
import { embed, tokenize } from "@/lib/ai";

import { getDB, relate } from "@/lib/db";
import { isSlashCommand, trimSlashCommand } from "@/lib/util/command-format";
import processCommand from "@/lib/util/command";
import parsePostContentNew from "@/lib/util/parse-post-content-new";
import { createFiles } from "@/lib/database/file";
import createLog from "@/lib/database/log";
import { getEntity, getLatest } from "@/lib/database/helpers";
import { RecordId, StringRecordId } from "surrealdb.js";
import {
  agentResponse,
  aggregateResponse,
  updateAgent,
} from "@/lib/database/agent";
import { toolResponse } from "@/lib/database/tool";

import { replaceContentWithLinks } from "@/lib/database/helpers";

import hash from "@/lib/util/hash";

import TOOLS from "@/hashtools/mod";

import { tail } from "@/lib/util/forwards";

export const getConversation = async (
  post?: Post,
  depth: number = -1,
): Promise<Post[]> => {
  const db = await getDB();
  if (!post) {
    return [];
  }

  try {
    const posts = [];
    let currentPost = post;
    let count = 0;
    while (true) {
      if (depth > -1 && count >= depth) {
        break;
      }
      count++;
      posts.push(currentPost);
      if (!currentPost.target) {
        break;
      }
      let T = currentPost.target;
      // Target is actually a post id and not a post
      if ((currentPost.target as unknown as RecordId).tb) {
        [[T]] = await db.query<[[Post]]>(
          `SELECT * FROM ${TABLE_POST} WHERE id = $target`,
          { target: currentPost.target },
        );
      }
      currentPost = T;
    }
    return posts;
  } finally {
    await db.close();
  }
};

import { vectorSum } from "@/lib/util/vector-sum";

export const getRelevant = async ({
  conversation,
  agent,
  limit = 8,
  threshold = 0,
  embeddingMethod = "concat",
}: {
  conversation: Post[];
  agent: Agent;
  limit?: number;
  threshold?: number;
  embeddingMethod?: string;
}): Promise<Post[]> => {
  const queries = [];
  queries.push(
    `SELECT content, vector::similarity::cosine(embedding, $embedded) AS dist OMIT embedding FROM ${TABLE_POST} WHERE <-${REL_CONTAINS}<-${TABLE_FILE}<-${REL_BOOKMARKS}<-(${TABLE_AGENT} WHERE id = $id) AND dist > $threshold ORDER BY dist DESC LIMIT $limit`,
  );
  queries.push(
    `SELECT content, vector::similarity::cosine(embedding, $embedded) AS dist OMIT embedding FROM ${TABLE_POST} WHERE <-${REL_REMEMBERS}<-(${TABLE_AGENT} WHERE id = $id) AND dist > $threshold ORDER BY dist DESC LIMIT $limit`,
  );

  const db = await getDB();
  try {
    let embedded;
    switch (embeddingMethod) {
      case "concat":
        embedded = await embed(
          conversation
            .map(({ content }) => content)
            .join("\n\n"),
        );
        break;
      case "sum":
        embedded = vectorSum(conversation.map(({ embedding }) => embedding));
        break;
      case "sum-geometric-reduction":
        // Each embeding is multiplied by a decreasing factor before summing
        const factor = 0.9;
        const embeddings = conversation.map(({ embedding }, i) =>
          embedding.map((x) => x * Math.pow(factor, i))
        );
        embedded = vectorSum(embeddings);
        break;
      case "sum-weighted":
        embedded = vectorSum(
          conversation.map(({ embedding }, i, conversation) =>
            embedding.map((x) =>
              x * (conversation.length - i + 1) / (conversation.length)
            )
          ),
        );
        break;
    }
    // TODO: what's a better way to get an embedding for a conversation?
    // Would we instead extract the embeddingd and add them?
    const [bookmarked, remembered] = await db.query<[Post[], Post[]]>(
      queries.join(";"),
      {
        id: agent.id,
        embedded,
        limit,
        threshold,
      },
    );
    return [...bookmarked, ...remembered];
  } finally {
    await db.close();
  }
};

///////

export const generatePost = async (
  {
    tools,
    target,
    streaming = false,
    source,
    bibliography,
    depth,
    forward,
    replaceRootMessage,
  }: {
    tools?: string[];
    target?: Post;
    streaming?: boolean;
    source?: Agent;
    bibliography?: Post[];
    depth?: number;
    forward?: Forward;
    replaceRootMessage?: string;
  },
): Promise<Post> => {
  // content will be generated by a tool or an agent.

  const db = await getDB();
  try {
    bibliography = bibliography || [];
    const conversation = await getConversation(target, -1);
    let relevant: Post[] = [];
    let content;
    let mentions;
    let out;
    if (source) {
      if (conversation.length) {
        relevant = await getRelevant(
          { conversation, agent: source },
        );
      }
      if (!source.content) {
        source = await updateAgent(source.id, source);
      }
      out = await agentResponse(source, {
        streaming,
        conversation,
        relevant,
        replaceRootMessage,
      });
    }
    if (streaming) {
      const chunks = [];
      for await (const chunk of out as LangchainGenerator) {
        chunks.push(chunk);
      }
      content = chunks.join("\n");
    } else {
      const chunk = out as BaseMessageChunk;
      content = chunk.content as string;
    }
    const post = await createPost(content, {
      source,
      target,
      streaming,
      tools,
      bibliography: bibliography.concat(conversation).concat(relevant),
      depth,
      forward,
    }) as Post;
    return post;
  } catch (e) {
    console.error("XXXX", e);
  } finally {
    db.close();
  }
};

export const aggregatePostReplies = async (
  { source, target, streaming = false }: {
    source: Agent;
    target: Post;
    streaming?: boolean;
  },
): Promise<Post> => {
  const db = await getDB();
  try {
    if (!source.content) {
      source = await updateAgent(source.id, source);
    }
    const out = await aggregateResponse(source, target, { streaming });
    let content;
    if (streaming) {
      const chunks = [];
      for await (const chunk of out as LangchainGenerator) {
        chunks.push(chunk);
      }
      content = chunks.join("\n");
    } else {
      const chunk = out as BaseMessageChunk;
      content = chunk.content as string;
    }
    const [post] = await db.create(TABLE_POST, {
      timestamp: Date.now(),
      content,
      embedding: await embed(content),
      count: tokenize(content).length,
      hash: hash(content),
      source: source ? source.id : undefined,
      target: target ? target.id : undefined,
    }) as Post[];
    return replaceContentWithLinks(post);
  } finally {
    db.close();
  }
};

export const stringIdToAgent = async (id: string): Promise<Agent> => {
  const db = await getDB();
  try {
    const [[agent]] = await db.query<[[Agent]]>(
      `SELECT * FROM ${TABLE_AGENT} WHERE id = $id`,
      { id: new StringRecordId(id) },
    );
    return agent;
  } finally {
    await db.close();
  }
};

const processContent = (content: string, {
  embedding,
  source,
  files = [],
  tools,
  target,
  streaming = false,
  depth = 2 ** 2,
  dropLog = false,
  bibliography,
  forward = [],
}: {
  embedding?: number[];
  source?: Agent;
  files?: FileProto[];
  tools?: string[];
  target?: Post;
  streaming?: boolean;
  depth?: number;
  dropLog?: boolean;
  bibliography?: Post[];
  forward?: Forward;
} = {}): Promise<Post> => {
  return new Promise(async (rs, rj) => {
    if (depth === 0) {
      throw new Error("Depth limit reached.");
    }
    depth -= 1;
    let resolved = false;
    let rejected = false;
    const resolve = (post: Post) => {
      if (!resolved) {
        rs(post);
        resolved = true;
      }
    };
    const reject = (e: unknown) => {
      if (!resolved) {
        rj(e);
        resolved = true;
        rejected = true;
      }
    };
    const db = await getDB();
    try {
      let { original, dehydrated, sequential, simultaneous }: {
        original?: string;
        dehydrated?: string;
        sequential?: Forward[];
        simultaneous?: Forward[];
      } = await parsePostContentNew(content, forward);
      let post;
      for (let [toolName] of sequential) {
        toolName = toolName.slice(1);
        const [t, query] = (toolName as string).split("?");
        const params = Object.fromEntries(new URLSearchParams(query).entries());
        const tool = TOOLS[t as string];
        if (!tool) {
          continue;
        }
        const { handler, name, description } = tool;
        // TODO: Process Post
        console.log("Processing Post:");
        console.log(`${name} ${description} w/ ${toolName} `);
        const result = await handler(
          {
            embedding,
            source,
            files,
            tools,
            target,
            streaming,
            depth,
            dropLog,
            bibliography,
            forward,
            dehydrated,
            original,
            simultaneous,
            name,
            params,
          },
        );
        ({ post, dehydrated, simultaneous = [], files = [] } = result);
        if (post) {
          resolve(post);
        }
      }
      if (dehydrated || files.length) {
        post = await createPost(dehydrated, {
          embedding,
          source,
          files,
          tools,
          target,
          streaming,
          depth,
          dropLog,
          bibliography,
          forward: simultaneous,
          logCreation: resolved,
          noProcess: true,
        }) as Post;
        resolve(post);
      }
      for (const sim of simultaneous) {
        const source = await stringIdToAgent(sim[0] as string);
        const forward = tail(sim);
        createPost(false, {
          source,
          target: post,
          depth,
          streaming,
          bibliography,
          forward,
        });
      }
    } catch (e) {
      reject(e);
    } finally {
      await db.close();
    }
  });
};

import type { Forward } from "@/lib/util/forwards";

export const createPost = async (
  content: string | undefined | false | null,
  {
    embedding,
    source,
    files = [],
    tools: inputTools, //remove
    target,
    streaming = false,
    depth = 2 ** 2,
    dropLog = false,
    bibliography,
    forward = [],
    replaceRootMessage,
    logCreation = false,
    noProcess = false,
  }: {
    embedding?: number[];
    source?: Agent;
    files?: FileProto[];
    tools?: string[]; //remove
    target?: Post;
    streaming?: boolean;
    depth?: number;
    dropLog?: boolean;
    bibliography?: Post[];
    forward?: Forward;
    replaceRootMessage?: string;
    logCreation?: boolean;
    noProcess?: boolean;
  } = {},
): Promise<Entity | void> => {
  const db = await getDB();
  try {
    let post: Post;

    if (content && !noProcess) {
      // create a message
      if (isSlashCommand(content)) {
        return processCommand(trimSlashCommand(content), {
          files,
          target,
          source,
          dropLog,
        });
      } else {
        // create a post from content
        post = await processContent(content, {
          embedding,
          source,
          files,
          tools: inputTools, //remove
          target,
          streaming,
          depth,
          dropLog,
          bibliography,
          forward,
        });
      }
    } else if (content === null) {
      // temporary content will be created later.
      [post] = await db.create(TABLE_POST, {
        timestamp: Date.now(),
        embedding: await embed(""),
        source: source ? source.id : undefined,
        target: target ? target.id : undefined,
        bibliography,
      }) as Post[];
    } else if (content === false) {
      // content will be generated by a tool or an agent.
      post = await generatePost({
        tools: inputTools,
        target,
        streaming,
        source,
        bibliography,
        depth,
        forward,
        replaceRootMessage,
      });
    } else if (!content || noProcess) {
      if (!content && !files.length) {
        throw new Error("No content or files provided.");
      }
      const createdFiles = await createFiles({ files, owner: source });
      const filesIds = createdFiles.map(({ id }) => id);
      const fileContent = createdFiles.map(({ content }) => content);
      const mentions: Agent[] = [];
      for (const sim of forward) {
        mentions.push(await stringIdToAgent(sim[0] as string));
      }
      const finalContent = content || "";
      const phantomContents =
        (content ? [content].concat(fileContent) : fileContent).join("\n");
      [post] = await db
        .create(TABLE_POST, {
          timestamp: Date.now(),
          content: finalContent || "",
          embedding: embedding ? embedding : await embed(phantomContents),
          count: tokenize(finalContent).length,
          hash: hash(phantomContents),
          files: filesIds,
          mentions: mentions.map(({ id }) => id),
          source: source ? source.id : undefined,
          target: target ? target.id : undefined,
          bibliography,
        }) as Post[];
    } else {
      throw new Error("Invalid content provided.");
    }
    if (logCreation) {
      createLog(post, { drop: dropLog });
    }
    if (source) {
      await relate(source.id, REL_INSERTED, post.id);
    }
    if (target) {
      await relate(target.id, REL_ELICITS, post.id);
    }
    return replaceContentWithLinks(post);
  } finally {
    await db.close();
  }
};

export const updatePendingPost = async (
  id: RecordId,
  {
    content,
    embedding,
    files = [],
    source,
    forward = [],
  }: {
    content?: string;
    embedding?: number[];
    files?: FileProto[];
    source?: Agent;
    forward?: Forward[];
  } = {},
): Promise<Post> => {
  if (!(content || "").trim()) {
    throw new Error("Content is required to update a post.");
  }
  const db = await getDB();
  try {
    // TODO: what to do with the rest of the data
    // sequential? original?,

    const { dehydrated }: {
      original?: string;
      dehydrated?: string;
      sequential?: Forward[];
      simultaneous?: Forward[];
    } = await parsePostContentNew(content!, forward);
    const mentions: Agent[] = [];
    for (const sim of forward) {
      mentions.push(await stringIdToAgent(sim[0] as string));
    }
    const content_ = dehydrated;
    const post = await db.update(id, {
      timestamp: Date.now(),
      hash: hash(content_),
      content: content_,
      embedding: embedding ? embedding : await embed(content_),
      source,
      mentions: mentions.map(({ id }) => id),
    }) as Post;
    await createFiles({ files, owner: source });
    return replaceContentWithLinks(post);
  } finally {
    await db.close();
  }
};

export const getPost = getEntity<Post>;
export const getPosts = getLatest<Post>(TABLE_POST);

export const replaceAgentIdWithName = async (
  id: string,
): Promise<string | null> => {
  const db = await getDB();

  try {
    try {
      const [[agent]]: Agent[][] = await db.query(
        `SELECT name FROM ${TABLE_AGENT} WHERE id = $id`,
        {
          id: new StringRecordId(id),
        },
      );
      return agent ? agent.name : id;
    } catch (e) {
      console.error(e);
      return id;
    }
  } finally {
    await db.close();
  }
};

const ADDITIONAL_FIELDS =
  `string::concat("", id) as id, IF source IS NOT NULL AND source IS NOT NONE THEN {id:string::concat("", source.id), name:source.name, hash:source.hash, image:source.image} ELSE NULL END AS source
    `;

export const getPostPlus = async (id: StringRecordId): Promise<PostPlus> => {
  const queries = [];

  // select target
  queries.push(
    `SELECT *, ${ADDITIONAL_FIELDS} OMIT embedding, data FROM post where id = $id FETCH source, target, target.mentions, target.bibliography, target.source, mentions, mentions.bibliography, bibliography, bibliography.mentions`,
  );
  // select incoming relationships
  // precedes
  queries.push(
    `SELECT *, ${ADDITIONAL_FIELDS} OMIT embedding, data FROM post where ->${REL_PRECEDES}->(post where id = $id)`,
  );
  // // select outgoing relationships
  // // precedes
  queries.push(
    `SELECT *, ${ADDITIONAL_FIELDS} OMIT embedding, data FROM post where <-${REL_PRECEDES}<-(post where id = $id)`,
  );
  // // elicits
  queries.push(
    `SELECT *, ${ADDITIONAL_FIELDS} OMIT embedding, data FROM post where <-${REL_ELICITS}<-(post where id = $id) FETCH mentions`,
  );
  // // remembers
  queries.push(
    `SELECT *, ${ADDITIONAL_FIELDS} OMIT embedding, data FROM agent where <-${REL_REMEMBERS}<-(post where id = $id)`,
  );

  // // container
  queries.push(
    `SELECT *, ${ADDITIONAL_FIELDS} OMIT embedding, data FROM file where ->${REL_CONTAINS}->(post where id = $id)`,
  );

  const db = await getDB();
  try {
    const [
      [post],
      [before],
      [after],
      elicits,
      remembers,
      [container],
    ]: [[Post], [Post], [Post], Post[], Agent[], [File]] = await db
      .query(queries.join(";"), {
        id,
      });
    if (post.target) {
      post.target = replaceContentWithLinks(post.target);
    }

    const obj: PostPlus = {
      post: replaceContentWithLinks(post, true),
      before: before ? replaceContentWithLinks(before, true) : undefined,
      after: after ? replaceContentWithLinks(after, true) : undefined,
      elicits: elicits
        ? await Promise.all(
          elicits.filter((x) => x).map((post) =>
            replaceContentWithLinks(post, true)
          ),
        )
        : undefined,
      remembers,
      container,
    };

    return obj;
  } finally {
    await db.close();
  }
};
const CLONE_FORBIDDEN_KEYS = ["id", "timestamp"];

// export type Keeper = "mentions" | "tools" | "source" | "target" | "container";

export type Keeper = string;

export const clonePost = async (
  post: Post,
  keep?: Keeper[],
  update: Partial<Post> = {},
): Promise<Post> => {
  // const props: Omit<Post, "id" | "timestamp"> = {
  //   content: post.content,
  //   embedding: post.embedding,
  //   count: post.count,
  //   hash: post.hash,
  // };
  const props: Record<string, any> = {
    content: post.content,
    embedding: post.embedding,
    count: post.count,
    hash: post.hash,
  };
  for (const k of keep || []) {
    if (CLONE_FORBIDDEN_KEYS.includes(k)) {
      throw new Error(`Cannot keep$ ${k} in clone.`);
    }
    if (!(k in post)) {
      throw new Error(`Property ${k} not found in post.`);
    }
    props[k as keyof Post] = post[k as keyof Post];
  }
  if (update.source) {
    props.source = update.source;
  }
  const db = await getDB();
  try {
    const [clone] = await db.create(TABLE_POST, {
      timestamp: Date.now(),
      ...props,
    }) as Post[];
    return replaceContentWithLinks(clone);
  } finally {
    await db.close();
  }
};

export default createPost;
